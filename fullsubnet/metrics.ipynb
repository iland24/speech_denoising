{"cells":[{"cell_type":"code","source":["'''\n","Metrics.ipynb \n","This script takes a set of audio file pairs. \n","The pair can be clean and noisy pair or clean and enhanced version of noisy pair.\n","Clean and noisy files are compared to generate these evaluation metrics to measure\n","the speech quality of the noisy files.\n","'''"],"metadata":{"id":"S-H4SCZw1eRE"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c_LyFFV5RI7l"},"outputs":[],"source":["!pip install numpy==1.21.6\n","!pip3 install https://github.com/schmiph2/pysepm/archive/master.zip --quiet\n","!pip3 install pystoi --quiet\n","!pip install git+https://github.com/aliutkus/speechmetrics"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"x3eTIZZrRL7r","executionInfo":{"status":"ok","timestamp":1683151911906,"user_tz":-540,"elapsed":2,"user":{"displayName":"Daniel Lee","userId":"05387762087311196943"}}},"outputs":[],"source":["import pysepm\n","import pystoi\n","import speechmetrics\n","import librosa\n","import numpy as np\n","import os\n","import glob\n","import re"]},{"cell_type":"code","source":["# set path to the noisy and clean data pair you want to calcualte the evaluation metrics\n","path_to_noisy_data = '/content/test_data/src_noisy/'\n","path_to_clean_data = '/content/test_data/src_clean/'"],"metadata":{"id":"SgVzjbR-sImB","executionInfo":{"status":"ok","timestamp":1683152304495,"user_tz":-540,"elapsed":2,"user":{"displayName":"Daniel Lee","userId":"05387762087311196943"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","execution_count":37,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1683153534503,"user":{"displayName":"Daniel Lee","userId":"05387762087311196943"},"user_tz":-540},"id":"sfoQtYE954bl"},"outputs":[],"source":["clean_filenames = glob.glob(path_to_clean_data + \"*.wav\")\n","noisy_filenames = glob.glob(path_to_noisy_data + \"*.wav\")\n","\n","# Retrieve only the file names, not the paths\n","for i in range(len(noisy_filenames)): \n","  name = noisy_filenames[i]\n","  n = re.findall('[a-zA-Z0-9_.-]+$',name)[0]\n","  noisy_filenames[i]=n\n","\n","for i in range(len(clean_filenames)): \n","  name = clean_filenames[i]\n","  n = re.findall('[a-zA-Z0-9_.-]+$',name)[0]\n","  clean_filenames[i]=n"]},{"cell_type":"code","execution_count":48,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1683153725367,"user":{"displayName":"Daniel Lee","userId":"05387762087311196943"},"user_tz":-540},"id":"z5kXd1v15fZB"},"outputs":[],"source":["'''\n","Here, we align clean and noisy audio pair based on the id of the files.\n","Dns challenge test audio file names include ids that ranges from 0 to 300.\n","We use regular expression to find the ids attached at the end of each file.\n","'''\n","\n","sorted_clean=[None]*301\n","sorted_noisy=[None]*301\n","\n","for i in range(len(clean_filenames)): \n","  name = clean_filenames[i]\n","  n = re.findall('[0-9]+',name)[-1]\n","  sorted_clean[int(n)] = name\n","\n","for i in range(len(noisy_filenames)):\n","  name = noisy_filenames[i]\n","  n = re.findall('[0-9]+',name)[-1]\n","  sorted_noisy[int(n)] = name\n","\n","sorted_clean = [i for i in sorted_clean if i is not None]    \n","sorted_noisy = [i for i in sorted_noisy if i is not None]    \n"]},{"cell_type":"code","execution_count":51,"metadata":{"id":"tPCsP1RA8E-S","executionInfo":{"status":"ok","timestamp":1683153814562,"user_tz":-540,"elapsed":1068,"user":{"displayName":"Daniel Lee","userId":"05387762087311196943"}}},"outputs":[],"source":["# Using librosa package, store sampled version (sampling rate = 16000) of each file \n","clean_data=[]\n","for fname in sorted_clean:\n","  clean_data.append(librosa.load(path_to_clean_data+fname, sr=16000)[0])\n","\n","noisy_data=[]\n","for fname in sorted_noisy:\n","  noisy_data.append(librosa.load(path_to_noisy_data+fname, sr=16000)[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jlZ_fFENpGWc"},"outputs":[],"source":["# Calculate mean PYSEPM metrics of all the clean & noisy pairs \n","\n","y01_ls = np.zeros(len(clean_data))\n","y02_ls = np.zeros(len(clean_data))\n","y03_ls = np.zeros(len(clean_data))\n","y04_ls = np.zeros(len(clean_data))\n","y05_ls = np.zeros(len(clean_data))\n","y06_ls = np.zeros(len(clean_data))\n","y07_ls = np.zeros(len(clean_data))\n","y08_ls = np.zeros(len(clean_data))\n","y09_ls = np.zeros(len(clean_data))\n","y10_ls = np.zeros(len(clean_data))\n","y11_ls = np.zeros(len(clean_data))\n","\n","for i in range(len(clean_data)): \n","    clean = clean_data[i]\n","    noisy = noisy_data[i]\n","    \n","    Y01, Y02, Y03 = pysepm.composite(clean, noisy, 16000)\n","    Y04, Y05, Y06 = pysepm.csii(clean, noisy, 16000)\n","    Y07           = pysepm.fwSNRseg(clean, noisy, 16000)\n","    Y08           = pysepm.SNRseg(clean, noisy, 16000)\n","    Y09           = pysepm.llr(clean, noisy, 16000)\n","    Y10           = pysepm.ncm(clean, noisy, 16000)\n","    Y11           = pysepm.wss(clean, noisy, 16000)\n","\n","    y01_ls[i]=(Y01)\n","    y02_ls[i]=(Y02)\n","    y03_ls[i]=(Y03)\n","    y04_ls[i]=(Y04)\n","    y05_ls[i]=(Y05)\n","    y06_ls[i]=(Y06)\n","    y07_ls[i]=(Y07)\n","    y08_ls[i]=(Y08)\n","    y09_ls[i]=(Y09)\n","    y10_ls[i]=(Y10)\n","    y11_ls[i]=(Y11)\n","\n","### PRINT mean\n","print(\n","  \"\\n\",\n","  \"Composite \", np.mean(y01_ls), \"    \", np.mean(y02_ls), \"    \", np.mean(y03_ls), \"\\n\",\n","  \"CSII      \", np.mean(y04_ls), \"    \", np.mean(y05_ls), \"    \", np.mean(y06_ls), \"\\n\",\n","  \"fwSNRseg  \", np.mean(y07_ls), \"\\n\",\n","  \"SNRseg    \", np.mean(y08_ls), \"\\n\",\n","  \"LLR       \", np.mean(y09_ls), \"\\n\",\n","  \"NCM       \", np.mean(y10_ls), \"\\n\",\n","  \"WSS       \", np.mean(y11_ls),\n","  sep=\"\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jGjgc84I-mpP"},"outputs":[],"source":["# Calculate mean SPEECHMETRICS & PYSEPM metrics of all the clean & noisy pairs \n","y12_to_20 = np.zeros((9))\n","\n","for i in range(len(clean_data)): \n","    clean = clean_data[i]\n","    noisy = noisy_data[i]\n","        \n","    Y12, Y13, Y14, Y15, Y16, Y17, Y18 = speechmetrics.load(\n","        'relative', window=None)(noisy, clean, rate=16000).values()\n","\n","    Y12, Y13, Y14 = Y12.item(), Y13.item(), Y14.item()\n","\n","    Y19, Y20 = speechmetrics.load(\n","        'absolute', window=None)(noisy, rate=16000).values()\n","\n","    Y19 = Y19.item()\n","\n","    y12_to_20[0]+=(Y12)\n","    y12_to_20[1]+=(Y13)\n","    y12_to_20[2]+=(Y14)\n","    y12_to_20[3]+=(Y15)\n","    y12_to_20[4]+=(Y16)\n","    y12_to_20[5]+=(Y17)\n","    y12_to_20[6]+=(Y18)\n","    y12_to_20[7]+=(Y19)\n","    y12_to_20[8]+=(Y20)\n","\n","### PRINT mean\n","print(\"SDR: \", np.mean(y12_to_20[0]))\n","print(\"ISR:   \", np.mean(y12_to_20[1]))\n","print(\"SAR: \", np.mean(y12_to_20[2]))\n","print(\"NB_PESQ: \", np.mean(y12_to_20[3]))\n","print(\"PESQ: \", np.mean(y12_to_20[4]))\n","print(\"SISDR: \", np.mean(y12_to_20[5]))\n","print(\"STOI: \", np.mean(y12_to_20[6]))\n","print(\"MOSNET: \", np.mean(y12_to_20[7]))\n","print(\"SRMR: \", np.mean(y12_to_20[8]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i0do3gTr-tRH"},"outputs":[],"source":["# Calculate mean PYSTOI metrics of all the clean & noisy pairs \n","\n","y23_to_24 = np.zeros((2))\n","for i in range(len(clean_data)): \n","    clean = clean_data[i]\n","    noisy = noisy_data[i]\n","\n","    Y23 = pystoi.stoi(clean, noisy, fs_sig=16000, extended=False)\n","    Y24 = pystoi.stoi(clean, noisy, fs_sig=16000, extended=True)\n","\n","    y23_to_24[0]+=Y23\n","    y23_to_24[1]+=Y24\n","    \n","### PRINT\n","\n","print(\n","    \"STOI   \", np.mean(y23_to_24[0]), \"\\n\",\n","    \"ESTOI  \", np.mean(y23_to_24[1]),\n","    sep=\"\"\n",")"]}],"metadata":{"colab":{"provenance":[{"file_id":"1gb6EP8AFcw1l8Pwc5J6MzRQQg5m7NeDd","timestamp":1679246152796},{"file_id":"1AiDIMgPIvdwaBSCohWwJtvlzbdSIq0ZE","timestamp":1678809805004}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}