{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1Nz6BNujtK46ZegS0VlGqm5O22ijNvqjR","timestamp":1681845736189},{"file_id":"1VxXJgR9IXycgri0IdLPMIu6CcEwMkJL1","timestamp":1681709197569},{"file_id":"1RGC_G2JqUh7jLiRRSdquQqlHbq2pgHh0","timestamp":1677960349558},{"file_id":"1PVklx-iXi9uz96C4BHwLoDgnYurlBEpa","timestamp":1677904553895}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["```\n","11785-spring23-projects\n","├── eval\n","│   ├── radix\n","│   │   └── dns\n","│   │       └── source\n","│   │           ├── radix_dns_source_clean\n","│   │           └── radix_dns_source_noisy\n","│   └── relay\n","│       ├── slack\n","│       │   └── cloud\n","│       │       ├── src_slack_relay_auto\n","│       │       └── src_slack_relay_low\n","│       └── teams\n","│           ├── cloud\n","│           │   ├── src_teams_cloud_relay_auto\n","│           │   └── src_teams_cloud_relay_low\n","│           └── phone\n","│               ├── src_teams_phone_relay_auto\n","│               └── src_teams_phone_relay_low\n","└── train\n","    ├── radix\n","    │   └── dns\n","    │       └── source\n","    │           ├── radix_dns_source_clean\n","    │           └── radix_dns_source_noisy\n","    └── relay\n","        ├── slack\n","        │   └── cloud\n","        │       ├── relay_slack_auto\n","        │       └── relay_slack_low\n","        └── teams\n","            ├── cloud\n","            │   ├── relay_teams_cloud_high\n","            │   └── relay_teams_cloud_low\n","            └── phone\n","                ├── relay_teams_phone_high\n","                └── relay_teams_phone_low\n","\n","\n","```"],"metadata":{"id":"N1ldd1A9lVUp"}},{"cell_type":"code","source":["import os\n","import glob\n","import re"],"metadata":{"id":"hePKokJAfGIq"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"44ejk5yNrNpK","outputId":"902aad0f-cd21-430a-9862-b7539b04bb34"},"outputs":[{"output_type":"stream","name":"stdout","text":["ing23-projects.zip   96%[==================> ]   9.58G  15.7MB/s    eta 28s    "]}],"source":["os.environ[\"PREFIX\"] = \"wget -q https://cmu.box.com/shared/static\"\n","os.environ[\"SUFFIX\"] = \"--content-disposition --show-progress\"\n","\n","!${PREFIX}/gwb1zmmrck3b5j5zbjpp303o6ij497at.zip ${SUFFIX}\n","!unzip -q 11785-spring23-projects.zip\n","\n","!${PREFIX}/tblaokesvar8mr6r38n36pqrhqp9gyko.tar ${SUFFIX}"]},{"cell_type":"code","source":["!wget https://github.com/YunyangZeng/TAPLoss/archive/refs/heads/master.zip\n","!unzip -q master.zip"],"metadata":{"id":"v0nMFbOpFlHd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682027960090,"user_tz":240,"elapsed":19090,"user":{"displayName":"Daniel Lee","userId":"05387762087311196943"}},"outputId":"f4c4889b-e191-4d8c-b75c-b69e20ea8fc8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-04-20 21:59:00--  https://github.com/YunyangZeng/TAPLoss/archive/refs/heads/master.zip\n","Resolving github.com (github.com)... 20.205.243.166\n","Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://codeload.github.com/YunyangZeng/TAPLoss/zip/refs/heads/master [following]\n","--2023-04-20 21:59:00--  https://codeload.github.com/YunyangZeng/TAPLoss/zip/refs/heads/master\n","Resolving codeload.github.com (codeload.github.com)... 20.205.243.165\n","Connecting to codeload.github.com (codeload.github.com)|20.205.243.165|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: unspecified [application/zip]\n","Saving to: ‘master.zip’\n","\n","master.zip              [   <=>              ] 122.53M  10.5MB/s    in 14s     \n","\n","2023-04-20 21:59:16 (8.76 MB/s) - ‘master.zip’ saved [128486388]\n","\n"]}]},{"cell_type":"code","source":["%cd /content/TAPLoss-master/FullSubNet/recipes/dns_interspeech_2020"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AIdaHWqAhIKk","executionInfo":{"status":"ok","timestamp":1682027960090,"user_tz":240,"elapsed":13,"user":{"displayName":"Daniel Lee","userId":"05387762087311196943"}},"outputId":"ef19164e-dc24-4fe8-a99b-a85e4b019492"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/TAPLoss-master/FullSubNet/recipes/dns_interspeech_2020\n"]}]},{"cell_type":"code","source":["!cp /content/TAPLoss-master/FullSubNet/recipes/dns_interspeech_2020/fullsubnet/trainer.py /content/TAPLoss-master/FullSubNet/"],"metadata":{"id":"-PzH5LvIcdp5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install rich \n","!pip install mir_eval \n","!pip install git+https://github.com/ludlows/python-pesq#egg=pesq \n","!pip install pypesq \n","!pip install pystoi \n","!pip install https://github.com/schmiph2/pysepm/archive/master.zip"],"metadata":{"id":"B1B7Kdag4sfm","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1682028028564,"user_tz":240,"elapsed":68484,"user":{"displayName":"Daniel Lee","userId":"05387762087311196943"}},"outputId":"3ad7473e-7a6c-477f-d7e0-5bb03e8c152f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: rich in /usr/local/lib/python3.9/dist-packages (13.3.4)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/dist-packages (from rich) (2.14.0)\n","Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /usr/local/lib/python3.9/dist-packages (from rich) (2.2.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.9/dist-packages (from markdown-it-py<3.0.0,>=2.2.0->rich) (0.1.2)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting mir_eval\n","  Downloading mir_eval-0.7.tar.gz (90 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.7/90.7 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.9/dist-packages (from mir_eval) (1.22.4)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from mir_eval) (1.10.1)\n","Requirement already satisfied: future in /usr/local/lib/python3.9/dist-packages (from mir_eval) (0.18.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from mir_eval) (1.16.0)\n","Building wheels for collected packages: mir_eval\n","  Building wheel for mir_eval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for mir_eval: filename=mir_eval-0.7-py3-none-any.whl size=100718 sha256=c2eb85775e107299829d7165adae9ee9e07bbf9ae3b243516b2889e8bc8cc5b8\n","  Stored in directory: /root/.cache/pip/wheels/e9/f5/d5/eb3db1d056253da195208853842bce745a84b29f44cab59b6c\n","Successfully built mir_eval\n","Installing collected packages: mir_eval\n","Successfully installed mir_eval-0.7\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pesq\n","  Cloning https://github.com/ludlows/python-pesq to /tmp/pip-install-0j3fe1ix/pesq_782a254675784f0391956eba4e1b0816\n","  Running command git clone --filter=blob:none --quiet https://github.com/ludlows/python-pesq /tmp/pip-install-0j3fe1ix/pesq_782a254675784f0391956eba4e1b0816\n","  Resolved https://github.com/ludlows/python-pesq to commit 5e230c59a3272fa80d8a6ea0d1e623f3fa560731\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: pesq\n","  Building wheel for pesq (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pesq: filename=pesq-0.0.4-cp39-cp39-linux_x86_64.whl size=257226 sha256=36371aef6e07ac4f6fae6eb16bc24266b3fbc8f0a6dad9ef747cc77f7226a6a3\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-u_oxz43n/wheels/ce/46/42/cc11ff939a88c6aaa81cd563e0a791afd6c11a75cd51ba6f23\n","Successfully built pesq\n","Installing collected packages: pesq\n","Successfully installed pesq-0.0.4\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pypesq\n","  Downloading pypesq-1.2.4.tar.gz (30 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from pypesq) (1.22.4)\n","Building wheels for collected packages: pypesq\n","  Building wheel for pypesq (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pypesq: filename=pypesq-1.2.4-cp39-cp39-linux_x86_64.whl size=94779 sha256=faa9ccf450ed582ec71b9acbc03b60898a5fc1b624e980787c1939940280ebf2\n","  Stored in directory: /root/.cache/pip/wheels/49/68/ac/12aee270f3f864ef148078b59db149f562a4a0eeaa9c6358d0\n","Successfully built pypesq\n","Installing collected packages: pypesq\n","Successfully installed pypesq-1.2.4\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pystoi\n","  Downloading pystoi-0.3.3.tar.gz (7.0 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from pystoi) (1.22.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from pystoi) (1.10.1)\n","Building wheels for collected packages: pystoi\n","  Building wheel for pystoi (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pystoi: filename=pystoi-0.3.3-py2.py3-none-any.whl size=7792 sha256=76bbab6588bec1d29e0ff93442ab996c1dca74d896eba188c22084a97a5a2c97\n","  Stored in directory: /root/.cache/pip/wheels/ca/b5/5b/ebb4c736d880f5726ad128c6a89b094ccb0eac84dac2c2ce88\n","Successfully built pystoi\n","Installing collected packages: pystoi\n","Successfully installed pystoi-0.3.3\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting https://github.com/schmiph2/pysepm/archive/master.zip\n","  Downloading https://github.com/schmiph2/pysepm/archive/master.zip\n","\u001b[2K     \u001b[32m-\u001b[0m \u001b[32m1.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m \u001b[33m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting pesq@ https://github.com/ludlows/python-pesq/archive/master.zip#egg=pesq\n","  Downloading https://github.com/ludlows/python-pesq/archive/master.zip\n","\u001b[2K     \u001b[32m-\u001b[0m \u001b[32m223.1 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m \u001b[33m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting SRMRpy@ https://github.com/jfsantos/SRMRpy/archive/master.zip#egg=SRMRpy\n","  Downloading https://github.com/jfsantos/SRMRpy/archive/master.zip\n","\u001b[2K     \u001b[32m-\u001b[0m \u001b[32m39.3 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m \u001b[33m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: pystoi in /usr/local/lib/python3.9/dist-packages (from pysepm==0.1) (0.3.3)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from pysepm==0.1) (1.10.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from pysepm==0.1) (1.22.4)\n","Requirement already satisfied: numba in /usr/local/lib/python3.9/dist-packages (from pysepm==0.1) (0.56.4)\n","Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.9/dist-packages (from numba->pysepm==0.1) (0.39.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from numba->pysepm==0.1) (67.6.1)\n","Collecting Gammatone@ https://github.com/detly/gammatone/archive/master.zip#egg=Gammatone\n","  Downloading https://github.com/detly/gammatone/archive/master.zip\n","\u001b[2K     \u001b[32m\\\u001b[0m \u001b[32m59.4 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m \u001b[33m0:00:06\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting nose\n","  Downloading nose-1.3.7-py3-none-any.whl (154 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.7/154.7 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting mock\n","  Downloading mock-5.0.2-py3-none-any.whl (30 kB)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from Gammatone@ https://github.com/detly/gammatone/archive/master.zip#egg=Gammatone->SRMRpy@ https://github.com/jfsantos/SRMRpy/archive/master.zip#egg=SRMRpy->pysepm==0.1) (3.7.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->Gammatone@ https://github.com/detly/gammatone/archive/master.zip#egg=Gammatone->SRMRpy@ https://github.com/jfsantos/SRMRpy/archive/master.zip#egg=SRMRpy->pysepm==0.1) (4.39.3)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->Gammatone@ https://github.com/detly/gammatone/archive/master.zip#egg=Gammatone->SRMRpy@ https://github.com/jfsantos/SRMRpy/archive/master.zip#egg=SRMRpy->pysepm==0.1) (1.4.4)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->Gammatone@ https://github.com/detly/gammatone/archive/master.zip#egg=Gammatone->SRMRpy@ https://github.com/jfsantos/SRMRpy/archive/master.zip#egg=SRMRpy->pysepm==0.1) (3.0.9)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->Gammatone@ https://github.com/detly/gammatone/archive/master.zip#egg=Gammatone->SRMRpy@ https://github.com/jfsantos/SRMRpy/archive/master.zip#egg=SRMRpy->pysepm==0.1) (0.11.0)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->Gammatone@ https://github.com/detly/gammatone/archive/master.zip#egg=Gammatone->SRMRpy@ https://github.com/jfsantos/SRMRpy/archive/master.zip#egg=SRMRpy->pysepm==0.1) (8.4.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->Gammatone@ https://github.com/detly/gammatone/archive/master.zip#egg=Gammatone->SRMRpy@ https://github.com/jfsantos/SRMRpy/archive/master.zip#egg=SRMRpy->pysepm==0.1) (1.0.7)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->Gammatone@ https://github.com/detly/gammatone/archive/master.zip#egg=Gammatone->SRMRpy@ https://github.com/jfsantos/SRMRpy/archive/master.zip#egg=SRMRpy->pysepm==0.1) (2.8.2)\n","Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->Gammatone@ https://github.com/detly/gammatone/archive/master.zip#egg=Gammatone->SRMRpy@ https://github.com/jfsantos/SRMRpy/archive/master.zip#egg=SRMRpy->pysepm==0.1) (5.12.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->Gammatone@ https://github.com/detly/gammatone/archive/master.zip#egg=Gammatone->SRMRpy@ https://github.com/jfsantos/SRMRpy/archive/master.zip#egg=SRMRpy->pysepm==0.1) (23.1)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib->Gammatone@ https://github.com/detly/gammatone/archive/master.zip#egg=Gammatone->SRMRpy@ https://github.com/jfsantos/SRMRpy/archive/master.zip#egg=SRMRpy->pysepm==0.1) (3.15.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib->Gammatone@ https://github.com/detly/gammatone/archive/master.zip#egg=Gammatone->SRMRpy@ https://github.com/jfsantos/SRMRpy/archive/master.zip#egg=SRMRpy->pysepm==0.1) (1.16.0)\n","Building wheels for collected packages: pysepm, SRMRpy, Gammatone\n","  Building wheel for pysepm (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pysepm: filename=pysepm-0.1-py3-none-any.whl size=24306 sha256=bc50c9996cc02c567ce1825ed5ec2a126efe039726185173d3ccec4d4ce8f7fa\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-eoe7any_/wheels/28/ae/1d/19ccc0d05c4419b9d6441ad669c05a324b07a55db9a0ec7fe0\n","  Building wheel for SRMRpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for SRMRpy: filename=SRMRpy-1.0-py3-none-any.whl size=9387 sha256=44c168cb5650fa9dc17e6b410fe40cf72ab899eab3f76ec24629233e52e19a60\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-eoe7any_/wheels/55/b8/62/0617bc2cd230cd3f61597a9562c65d86c1011dcb98262b6c5e\n","  Building wheel for Gammatone (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for Gammatone: filename=Gammatone-1.0-py3-none-any.whl size=21787 sha256=11433118aebed86dde7274488ce11e64e28df2e0ac7ec934edba637c2ef9021a\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-eoe7any_/wheels/ba/de/25/e746071319d3ca267f491e29108942e52047c55606d8f6ccff\n","Successfully built pysepm SRMRpy Gammatone\n","Installing collected packages: nose, mock, Gammatone, SRMRpy, pysepm\n","Successfully installed Gammatone-1.0 SRMRpy-1.0 mock-5.0.2 nose-1.3.7 pysepm-0.1\n"]}]},{"cell_type":"code","source":["train_toml=\"\"\"\n","\n","[meta]\n","save_dir = \"{}\"\n","description = \"This is a description of FullSubNet finetuning with train partition 1.\"\n","seed = 0  # set random seed for random, numpy, pytorch-gpu and pytorch-cpu\n","use_amp = true\n","cudnn_enable = false\n","\n","[acoustics]\n","n_fft = 512\n","win_length = 512\n","sr = 16000\n","hop_length = 256\n","\n","\n","[loss_function]\n","name = \"mse_loss\"\n","\n","[acoustic_loss]\n","ac_loss_weight = 0 # change to 1 to use acoustic loss with weight 1\n","ac_loss_only  = false\n","model_path   = \"{}\"\n","type = \"l1\"\n","\n","\n","[loss_function.args]\n","\n","\n","[optimizer]\n","lr = 0.00001\n","beta1 = 0.9\n","beta2 = 0.999\n","\n","\n","[train_dataset]\n","path = \"dataset_train.Dataset\"\n","[train_dataset.args]\n","clean_dataset = \"{}\"\n","clean_dataset_limit = false\n","clean_dataset_offset = 0\n","noise_dataset = \"TAPLoss-master/FullSubNet/recipes/Datasets/noise.txt\"\n","noise_dataset_limit = false\n","noise_dataset_offset = 0\n","num_workers =36\n","pre_load_clean_dataset = false\n","pre_load_noise = false\n","pre_load_rir = false\n","reverb_proportion = 0\n","rir_dataset = \"TAPLoss-master/FullSubNet/recipes/Datasets/rir.txt\"\n","rir_dataset_limit = false\n","rir_dataset_offset = 0\n","silence_length = 0\n","snr_range = [-5, 20]\n","sr = 16000\n","sub_sample_length = 3.072\n","target_dB_FS = -25\n","target_dB_FS_floating_value = 10\n","use_prepared_dataset = true\n","noisy_dataset = \"{}\"\n","\n","\n","[train_dataset.dataloader]\n","batch_size = 8\n","num_workers = 2\n","drop_last = true\n","pin_memory = false\n","\n","\n","[validation_dataset]\n","path = \"dataset_validation.Dataset\"\n","[validation_dataset.args]\n","dataset_dir_list = [\n","    \"{}\"\n","]\n","sr = 16000\n","\n","\n","[model]\n","path = \"fullsubnet.model.Model\"\n","\n","[model.args]\n","sb_num_neighbors = 15\n","fb_num_neighbors = 0\n","num_freqs = 257\n","look_ahead = 2\n","sequence_model = \"LSTM\"\n","fb_output_activate_function = \"ReLU\"\n","sb_output_activate_function = false\n","fb_model_hidden_size = 512\n","sb_model_hidden_size = 384\n","weight_init = false\n","norm_type = \"offline_laplace_norm\"\n","num_groups_in_drop_band = 1\n","\n","\n","[trainer]\n","path = \"trainer.Trainer\"\n","[trainer.train]\n","clip_grad_norm_value = 1\n","epochs = 10\n","save_checkpoint_interval = 1\n","[trainer.validation]\n","save_max_metric_score = true\n","validation_interval = 1\n","[trainer.visualization]\n","metrics = [\"WB_PESQ\", \"STOI\"]\n","n_samples = 10\n","num_workers = 4\n","\"\"\""],"metadata":{"id":"1itQX4IUMSeh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def make_training_config(\n","        training_toml_path        ,\n","        train_noisy_txt           ,\n","        test_noisy_path            ,\n","        train_clean_txt           ,\n","        test_clean_path            ,\n","        eval_dir                  ,\n","        learning_rate             ,\n","        acoustic_loss_weight      ,\n","        epochs                    ,\n","        num_workers               ,\n","        batch_size                ,\n","        checkpoint):\n","    \n","    save_dir = \"/\".join(training_toml_path[:-5].split(\"/\")[:-1]) + \"/out\"\n","\n","    try:\n","      os.mkdir(save_dir)\n","    except:\n","      pass \n","      \n","    train_toml2 = train_toml.format( \n","        save_dir,\n","        checkpoint,\n","        train_clean_txt,\n","        train_noisy_txt,\n","        eval_dir\n","     )\n","\n","    with open(training_toml_path, \"w\") as f:\n","        f.write(train_toml2)"],"metadata":{"id":"84TZGufAE6PE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def make_training_runner(\n","    training_voip_runner_path ,\n","    training_voip_config_path ,\n","    checkpoint                ):\n","\n","    nnodes         = 1\n","    nproc_per_node = 1\n","    train_toml     = training_voip_config_path\n","\n","    training_voip_runner_text = \"\"\"\n","    #!/bin/bash\n","\n","    torchrun                \\\n","        --standalone        \\\n","        --nnodes={}         \\\n","        --nproc_per_node={} \\\n","        train.py            \\\n","        -C {}               \\\n","        -P {}\n","    \"\"\".format(\n","        nnodes         ,\n","        nproc_per_node ,\n","        train_toml     ,\n","        checkpoint     )\n","\n","    with open(training_voip_runner_path, \"w\") as f:\n","        f.write(training_voip_runner_text)\n","\n","    return None"],"metadata":{"id":"7QZLe_Ab7HYq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def make_eval_dir_struct(\n","        test_noisy_path,\n","        test_clean_path):\n","  \n","    eval_dir = \"/\".join(test_noisy_path.split(\"/\")[:-1]) + \"/no_reverb/\"\n","    if not os.path.isdir(eval_dir):\n","      os.mkdir(eval_dir)\n","      os.mkdir(f\"{eval_dir}/noisy\")\n","      os.mkdir(f\"{eval_dir}/clean\")\n","      os.system(f\"cp -r {test_noisy_path}/*.wav {eval_dir}/noisy\")\n","      os.system(f\"cp -r {test_clean_path}/*.wav {eval_dir}/clean\")\n","    return eval_dir\n","\n","def setupTrainingRunner(\n","            training_runner_path     ,\n","            training_toml_path        ,\n","            train_noisy_txt           ,\n","            test_noisy_path           ,\n","            train_clean_txt           ,\n","            test_clean_path           ,\n","            learning_rate             ,\n","            acoustic_loss_weight      ,\n","            epochs                    ,\n","            num_workers               ,\n","            batch_size                ,\n","            checkpoint                ):\n","\n"," \n","    eval_dir = make_eval_dir_struct(\n","        test_noisy_path,\n","        test_clean_path\n","    )\n","\n","    make_training_config(\n","        training_toml_path        ,\n","        train_noisy_txt           ,\n","        test_noisy_path           ,\n","        train_clean_txt           ,\n","        test_clean_path           ,\n","        eval_dir                  ,\n","        learning_rate             ,\n","        acoustic_loss_weight      ,\n","        epochs                    ,\n","        num_workers               ,\n","        batch_size                ,\n","        checkpoint                )\n","\n","\n","    make_training_runner(\n","        training_runner_path ,\n","        training_toml_path ,\n","        checkpoint                )\n","\n","    return None"],"metadata":{"id":"VcLn14_ApYZc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def trainPartitions(\n","    training_toml_paths,\n","    train_noisy_txts    ,\n","    test_noisy_paths     ,\n","    train_clean_txt     ,\n","    test_clean_path      ,\n","    learning_rate        ,\n","    acoustic_loss_weight ,\n","    epochs               ,\n","    num_workers          ,\n","    batch_size           ,\n","    checkpoint           ):\n","\n","    for (train_noisy_txt, test_noisy_path, training_toml_path) in zip(train_noisy_txts, test_noisy_paths, training_toml_paths):\n","        # loop through all \n","\n","        training_runner_path = training_toml_path[:-5] + \".sh\" # change .toml to .sh.  \n","        print(training_runner_path)\n","\n","        setupTrainingRunner(\n","            training_runner_path     ,\n","            training_toml_path        ,\n","            train_noisy_txt           ,\n","            test_noisy_path           ,\n","            train_clean_txt           ,\n","            test_clean_path           ,\n","            learning_rate             ,\n","            acoustic_loss_weight      ,\n","            epochs                    ,\n","            num_workers               ,\n","            batch_size                ,\n","            checkpoint                )\n","        \n","        os.environ[\"TRAINING_RUNNER_PATH\"] = training_runner_path\n","\n","        !sh {training_runner_path} # run using os\n","        break"],"metadata":{"id":"MAj7Zz3ArEk2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","GET_IDS = lambda p: int(re.split('_|\\.', p.split(\"fileid_\")[1])[0])\n","\n","# these are paths to test/train data\n","train_clean_path =\\\n","    \"/content/11785-spring23-projects/train/radix/dns/source/radix_dns_source_clean\"\n","\n","test_clean_path =\\\n","    \"/content/11785-spring23-projects/eval/radix/dns/source/radix_dns_source_clean\"\n","\n","train_noisy_paths = [\n","    \"/content/11785-spring23-projects/train/relay/teams/cloud/relay_teams_cloud_auto\", # there is no auto* only high\n","    \"/content/11785-spring23-projects/train/relay/teams/cloud/relay_teams_cloud_low\" ,\n","    ]\n","\n","test_noisy_paths = [\n","    \"/content/11785-spring23-projects/eval/relay/teams/cloud/src_teams_cloud_relay_auto\", # originally: relay_teams_cloud_auto\n","    \"/content/11785-spring23-projects/eval/relay/teams/cloud/src_teams_cloud_relay_low\",    # originally: relay_teams_cloud_low (but non-existent)\n","    ]\n","\n","training_toml_paths = [name + \".toml\" for name in train_noisy_paths]\n","print('training_toml_paths len:, ', len(training_toml_paths))\n","\n","# txt of paths to each text files\n","train_noisy_txts = [name + \".txt\" for name in train_noisy_paths]\n","print('tr noisy txts len:', len(train_noisy_txts))\n","\n","# path to tr clean txt file\n","# txt file contains the paths* to all clean files\n","train_clean_txt = train_clean_path + \".txt\"\n","print('train_clean_txt',train_clean_txt)\n","\n","# loop thorugh train clean&noisy paths\n","for path in [train_clean_path] + train_noisy_paths:\n","    # print(path) #=> path to each folder tr/radix or relay/dns or 3rd party software/ cloud or phone/ .... etc\n","    # writes the txt file there \n","    audio_paths = sorted(glob.glob(f\"{path}/*\"), key = GET_IDS)\n","    # print(audio_paths) # => paths to all the tr clean/noisy files\n","\n","    # write it into txt file (to find it later i guess)\n","    with open(f\"{path}.txt\", 'w') as f:\n","        for line in audio_paths:\n","            f.write(line)\n","            f.write('\\n')"],"metadata":{"id":"6UPPTN4N3KFu","executionInfo":{"status":"ok","timestamp":1682028333356,"user_tz":240,"elapsed":6,"user":{"displayName":"Daniel Lee","userId":"05387762087311196943"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"5204508b-a899-4cc2-9bc2-19e4b8594de9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["training_toml_paths len:,  1\n","tr noisy txts len: 1\n","train_clean_txt /content/11785-spring23-projects/train/radix/dns/source/radix_dns_source_clean.txt\n"]}]},{"cell_type":"code","source":["!pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NfyEhXPIKklF","executionInfo":{"status":"ok","timestamp":1682028334161,"user_tz":240,"elapsed":5,"user":{"displayName":"Daniel Lee","userId":"05387762087311196943"}},"outputId":"226f8d62-ad7f-4563-a557-e8abb062211f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/TAPLoss-master/FullSubNet/recipes/dns_interspeech_2020\n"]}]},{"cell_type":"code","source":["base = \"/content/\"\n","\n","learning_rate        = 1e-4\n","acoustic_loss_weight = 0.0\n","stft_loss_weight     = 1.0\n","epochs               = 10\n","num_workers          = 2\n","batch_size           = 10\n","\n","checkpoint = base + \"fullsubnet_best_model_58epochs.tar\"\n","\n","trainPartitions(\n","    training_toml_paths  ,\n","    train_noisy_txts     ,\n","    test_noisy_paths     ,\n","    train_clean_txt      ,\n","    test_clean_path      ,\n","    learning_rate        ,\n","    acoustic_loss_weight ,\n","    epochs               ,\n","    num_workers          ,\n","    batch_size           ,\n","    checkpoint           )"],"metadata":{"id":"7Ccfx4HMHSiW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682031371996,"user_tz":240,"elapsed":3037838,"user":{"displayName":"Daniel Lee","userId":"05387762087311196943"}},"outputId":"cc56fff5-caba-4ea5-d6c5-5168f054fae8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/11785-spring23-projects/train/relay/teams/cloud/relay_teams_cloud_low.sh\n","master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.\n","1 process initialized.\n","2023-04-20 22:05:42.141186: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-04-20 22:05:43.893999: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Model preloaded successfully from \u001b[35m/content/\u001b[0m\u001b[95mfullsubnet_best_model_58epochs.tar.\u001b[0m\n","The configurations are as follows: \n","\u001b[1m{\u001b[0m\n","    \u001b[32m'meta'\u001b[0m: \u001b[1m{\u001b[0m\n","        \u001b[32m'save_dir'\u001b[0m: \n","\u001b[32m'/content/11785-spring23-projects/train/relay/teams/cloud/out'\u001b[0m,\n","        \u001b[32m'description'\u001b[0m: \u001b[32m'This is a description of FullSubNet finetuning with \u001b[0m\n","\u001b[32mtrain partition 1.'\u001b[0m,\n","        \u001b[32m'seed'\u001b[0m: \u001b[1;36m0\u001b[0m,\n","        \u001b[32m'use_amp'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n","        \u001b[32m'cudnn_enable'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n","        \u001b[32m'experiment_name'\u001b[0m: \u001b[32m'relay_teams_cloud_low'\u001b[0m,\n","        \u001b[32m'config_path'\u001b[0m: \n","\u001b[32m'/content/11785-spring23-projects/train/relay/teams/cloud/relay_teams_cloud_low.\u001b[0m\n","\u001b[32mtoml'\u001b[0m,\n","        \u001b[32m'preloaded_model_path'\u001b[0m: \u001b[32m'/content/fullsubnet_best_model_58epochs.tar'\u001b[0m\n","    \u001b[1m}\u001b[0m,\n","    \u001b[32m'acoustics'\u001b[0m: \u001b[1m{\u001b[0m\n","        \u001b[32m'n_fft'\u001b[0m: \u001b[1;36m512\u001b[0m,\n","        \u001b[32m'win_length'\u001b[0m: \u001b[1;36m512\u001b[0m,\n","        \u001b[32m'sr'\u001b[0m: \u001b[1;36m16000\u001b[0m,\n","        \u001b[32m'hop_length'\u001b[0m: \u001b[1;36m256\u001b[0m\n","    \u001b[1m}\u001b[0m,\n","    \u001b[32m'loss_function'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'name'\u001b[0m: \u001b[32m'mse_loss'\u001b[0m, \u001b[32m'args'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n","    \u001b[32m'acoustic_loss'\u001b[0m: \u001b[1m{\u001b[0m\n","        \u001b[32m'ac_loss_weight'\u001b[0m: \u001b[1;36m0\u001b[0m,\n","        \u001b[32m'ac_loss_only'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n","        \u001b[32m'model_path'\u001b[0m: \u001b[32m'/content/fullsubnet_best_model_58epochs.tar'\u001b[0m,\n","        \u001b[32m'type'\u001b[0m: \u001b[32m'l1'\u001b[0m\n","    \u001b[1m}\u001b[0m,\n","    \u001b[32m'optimizer'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'lr'\u001b[0m: \u001b[1;36m1e-05\u001b[0m, \u001b[32m'beta1'\u001b[0m: \u001b[1;36m0.9\u001b[0m, \u001b[32m'beta2'\u001b[0m: \u001b[1;36m0.999\u001b[0m\u001b[1m}\u001b[0m,\n","    \u001b[32m'train_dataset'\u001b[0m: \u001b[1m{\u001b[0m\n","        \u001b[32m'path'\u001b[0m: \u001b[32m'dataset_train.Dataset'\u001b[0m,\n","        \u001b[32m'args'\u001b[0m: \u001b[1m{\u001b[0m\n","            \u001b[32m'clean_dataset'\u001b[0m: \n","\u001b[32m'/content/11785-spring23-projects/train/radix/dns/source/radix_dns_source_clean.\u001b[0m\n","\u001b[32mtxt'\u001b[0m,\n","            \u001b[32m'clean_dataset_limit'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n","            \u001b[32m'clean_dataset_offset'\u001b[0m: \u001b[1;36m0\u001b[0m,\n","            \u001b[32m'noise_dataset'\u001b[0m: \n","\u001b[32m'TAPLoss-master/FullSubNet/recipes/Datasets/noise.txt'\u001b[0m,\n","            \u001b[32m'noise_dataset_limit'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n","            \u001b[32m'noise_dataset_offset'\u001b[0m: \u001b[1;36m0\u001b[0m,\n","            \u001b[32m'num_workers'\u001b[0m: \u001b[1;36m36\u001b[0m,\n","            \u001b[32m'pre_load_clean_dataset'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n","            \u001b[32m'pre_load_noise'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n","            \u001b[32m'pre_load_rir'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n","            \u001b[32m'reverb_proportion'\u001b[0m: \u001b[1;36m0\u001b[0m,\n","            \u001b[32m'rir_dataset'\u001b[0m: \u001b[32m'TAPLoss-master/FullSubNet/recipes/Datasets/rir.txt'\u001b[0m,\n","            \u001b[32m'rir_dataset_limit'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n","            \u001b[32m'rir_dataset_offset'\u001b[0m: \u001b[1;36m0\u001b[0m,\n","            \u001b[32m'silence_length'\u001b[0m: \u001b[1;36m0\u001b[0m,\n","            \u001b[32m'snr_range'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1;36m-5\u001b[0m, \u001b[1;36m20\u001b[0m\u001b[1m]\u001b[0m,\n","            \u001b[32m'sr'\u001b[0m: \u001b[1;36m16000\u001b[0m,\n","            \u001b[32m'sub_sample_length'\u001b[0m: \u001b[1;36m3.072\u001b[0m,\n","            \u001b[32m'target_dB_FS'\u001b[0m: \u001b[1;36m-25\u001b[0m,\n","            \u001b[32m'target_dB_FS_floating_value'\u001b[0m: \u001b[1;36m10\u001b[0m,\n","            \u001b[32m'use_prepared_dataset'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n","            \u001b[32m'noisy_dataset'\u001b[0m: \n","\u001b[32m'/content/11785-spring23-projects/train/relay/teams/cloud/relay_teams_cloud_low.\u001b[0m\n","\u001b[32mtxt'\u001b[0m\n","        \u001b[1m}\u001b[0m,\n","        \u001b[32m'dataloader'\u001b[0m: \u001b[1m{\u001b[0m\n","            \u001b[32m'batch_size'\u001b[0m: \u001b[1;36m8\u001b[0m,\n","            \u001b[32m'num_workers'\u001b[0m: \u001b[1;36m2\u001b[0m,\n","            \u001b[32m'drop_last'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n","            \u001b[32m'pin_memory'\u001b[0m: \u001b[3;91mFalse\u001b[0m\n","        \u001b[1m}\u001b[0m\n","    \u001b[1m}\u001b[0m,\n","    \u001b[32m'validation_dataset'\u001b[0m: \u001b[1m{\u001b[0m\n","        \u001b[32m'path'\u001b[0m: \u001b[32m'dataset_validation.Dataset'\u001b[0m,\n","        \u001b[32m'args'\u001b[0m: \u001b[1m{\u001b[0m\n","            \u001b[32m'dataset_dir_list'\u001b[0m: \u001b[1m[\u001b[0m\n","                \u001b[32m'/content/11785-spring23-projects/eval/relay/teams/cloud/no_reve\u001b[0m\n","\u001b[32mrb/'\u001b[0m\n","            \u001b[1m]\u001b[0m,\n","            \u001b[32m'sr'\u001b[0m: \u001b[1;36m16000\u001b[0m\n","        \u001b[1m}\u001b[0m\n","    \u001b[1m}\u001b[0m,\n","    \u001b[32m'model'\u001b[0m: \u001b[1m{\u001b[0m\n","        \u001b[32m'path'\u001b[0m: \u001b[32m'fullsubnet.model.Model'\u001b[0m,\n","        \u001b[32m'args'\u001b[0m: \u001b[1m{\u001b[0m\n","            \u001b[32m'sb_num_neighbors'\u001b[0m: \u001b[1;36m15\u001b[0m,\n","            \u001b[32m'fb_num_neighbors'\u001b[0m: \u001b[1;36m0\u001b[0m,\n","            \u001b[32m'num_freqs'\u001b[0m: \u001b[1;36m257\u001b[0m,\n","            \u001b[32m'look_ahead'\u001b[0m: \u001b[1;36m2\u001b[0m,\n","            \u001b[32m'sequence_model'\u001b[0m: \u001b[32m'LSTM'\u001b[0m,\n","            \u001b[32m'fb_output_activate_function'\u001b[0m: \u001b[32m'ReLU'\u001b[0m,\n","            \u001b[32m'sb_output_activate_function'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n","            \u001b[32m'fb_model_hidden_size'\u001b[0m: \u001b[1;36m512\u001b[0m,\n","            \u001b[32m'sb_model_hidden_size'\u001b[0m: \u001b[1;36m384\u001b[0m,\n","            \u001b[32m'weight_init'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n","            \u001b[32m'norm_type'\u001b[0m: \u001b[32m'offline_laplace_norm'\u001b[0m,\n","            \u001b[32m'num_groups_in_drop_band'\u001b[0m: \u001b[1;36m1\u001b[0m\n","        \u001b[1m}\u001b[0m\n","    \u001b[1m}\u001b[0m,\n","    \u001b[32m'trainer'\u001b[0m: \u001b[1m{\u001b[0m\n","        \u001b[32m'path'\u001b[0m: \u001b[32m'trainer.Trainer'\u001b[0m,\n","        \u001b[32m'train'\u001b[0m: \u001b[1m{\u001b[0m\n","            \u001b[32m'clip_grad_norm_value'\u001b[0m: \u001b[1;36m1\u001b[0m,\n","            \u001b[32m'epochs'\u001b[0m: \u001b[1;36m10\u001b[0m,\n","            \u001b[32m'save_checkpoint_interval'\u001b[0m: \u001b[1;36m1\u001b[0m\n","        \u001b[1m}\u001b[0m,\n","        \u001b[32m'validation'\u001b[0m: \u001b[1m{\u001b[0m\n","            \u001b[32m'save_max_metric_score'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n","            \u001b[32m'validation_interval'\u001b[0m: \u001b[1;36m1\u001b[0m\n","        \u001b[1m}\u001b[0m,\n","        \u001b[32m'visualization'\u001b[0m: \u001b[1m{\u001b[0m\n","            \u001b[32m'metrics'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'WB_PESQ'\u001b[0m, \u001b[32m'STOI'\u001b[0m\u001b[1m]\u001b[0m,\n","            \u001b[32m'n_samples'\u001b[0m: \u001b[1;36m10\u001b[0m,\n","            \u001b[32m'num_workers'\u001b[0m: \u001b[1;36m4\u001b[0m\n","        \u001b[1m}\u001b[0m\n","    \u001b[1m}\u001b[0m\n","\u001b[1m}\u001b[0m\n","This project contains \u001b[1;36m1\u001b[0m models, the number of the parameters is: \n","        Network \u001b[1;36m1\u001b[0m: \u001b[1;36m5.637635\u001b[0m million.\n","The amount of parameters in the project is \u001b[1;36m5.637635\u001b[0m million.\n","=============== \u001b[1;36m1\u001b[0m epoch ===============\n","\u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m seconds\u001b[1m]\u001b[0m Begin training\u001b[33m...\u001b[0m\n","Training: 100% 150/150 [01:33<00:00,  1.60it/s]\n","         Saving \u001b[1;36m1\u001b[0m epoch model checkpoint\u001b[33m...\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[1;36m93\u001b[0m seconds\u001b[1m]\u001b[0m Training has finished, validation is in progress\u001b[33m...\u001b[0m\n","Validation: 150it [00:59,  2.51it/s]\n","/usr/local/lib/python3.9/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n","  return _methods._mean(a, axis=axis, dtype=dtype,\n","/usr/local/lib/python3.9/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n","  ret = ret.dtype.type(ret / rcount)\n","         Saving \u001b[1;36m1\u001b[0m epoch model checkpoint\u001b[33m...\u001b[0m\n","         😃 Found a best score in the \u001b[1;36m1\u001b[0m epoch, saving\u001b[33m...\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[1;36m305\u001b[0m seconds\u001b[1m]\u001b[0m This epoch is finished.\n","=============== \u001b[1;36m2\u001b[0m epoch ===============\n","\u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m seconds\u001b[1m]\u001b[0m Begin training\u001b[33m...\u001b[0m\n","Training: 100% 150/150 [01:28<00:00,  1.70it/s]\n","         Saving \u001b[1;36m2\u001b[0m epoch model checkpoint\u001b[33m...\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[1;36m88\u001b[0m seconds\u001b[1m]\u001b[0m Training has finished, validation is in progress\u001b[33m...\u001b[0m\n","Validation: 150it [00:59,  2.50it/s]\n","\u001b[1m[\u001b[0m\u001b[1;36m303\u001b[0m seconds\u001b[1m]\u001b[0m This epoch is finished.\n","=============== \u001b[1;36m3\u001b[0m epoch ===============\n","\u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m seconds\u001b[1m]\u001b[0m Begin training\u001b[33m...\u001b[0m\n","Training: 100% 150/150 [01:28<00:00,  1.69it/s]\n","         Saving \u001b[1;36m3\u001b[0m epoch model checkpoint\u001b[33m...\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[1;36m88\u001b[0m seconds\u001b[1m]\u001b[0m Training has finished, validation is in progress\u001b[33m...\u001b[0m\n","Validation: 150it [00:59,  2.50it/s]\n","\u001b[1m[\u001b[0m\u001b[1;36m300\u001b[0m seconds\u001b[1m]\u001b[0m This epoch is finished.\n","=============== \u001b[1;36m4\u001b[0m epoch ===============\n","\u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m seconds\u001b[1m]\u001b[0m Begin training\u001b[33m...\u001b[0m\n","Training: 100% 150/150 [01:27<00:00,  1.71it/s]\n","         Saving \u001b[1;36m4\u001b[0m epoch model checkpoint\u001b[33m...\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[1;36m88\u001b[0m seconds\u001b[1m]\u001b[0m Training has finished, validation is in progress\u001b[33m...\u001b[0m\n","Validation: 150it [00:59,  2.50it/s]\n","\u001b[1m[\u001b[0m\u001b[1;36m301\u001b[0m seconds\u001b[1m]\u001b[0m This epoch is finished.\n","=============== \u001b[1;36m5\u001b[0m epoch ===============\n","\u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m seconds\u001b[1m]\u001b[0m Begin training\u001b[33m...\u001b[0m\n","Training: 100% 150/150 [01:28<00:00,  1.70it/s]\n","         Saving \u001b[1;36m5\u001b[0m epoch model checkpoint\u001b[33m...\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[1;36m88\u001b[0m seconds\u001b[1m]\u001b[0m Training has finished, validation is in progress\u001b[33m...\u001b[0m\n","Validation: 150it [00:59,  2.52it/s]\n","\u001b[1m[\u001b[0m\u001b[1;36m300\u001b[0m seconds\u001b[1m]\u001b[0m This epoch is finished.\n","=============== \u001b[1;36m6\u001b[0m epoch ===============\n","\u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m seconds\u001b[1m]\u001b[0m Begin training\u001b[33m...\u001b[0m\n","Training: 100% 150/150 [01:28<00:00,  1.69it/s]\n","         Saving \u001b[1;36m6\u001b[0m epoch model checkpoint\u001b[33m...\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[1;36m88\u001b[0m seconds\u001b[1m]\u001b[0m Training has finished, validation is in progress\u001b[33m...\u001b[0m\n","Validation: 150it [01:00,  2.47it/s]\n","\u001b[1m[\u001b[0m\u001b[1;36m302\u001b[0m seconds\u001b[1m]\u001b[0m This epoch is finished.\n","=============== \u001b[1;36m7\u001b[0m epoch ===============\n","\u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m seconds\u001b[1m]\u001b[0m Begin training\u001b[33m...\u001b[0m\n","Training: 100% 150/150 [01:27<00:00,  1.71it/s]\n","         Saving \u001b[1;36m7\u001b[0m epoch model checkpoint\u001b[33m...\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[1;36m87\u001b[0m seconds\u001b[1m]\u001b[0m Training has finished, validation is in progress\u001b[33m...\u001b[0m\n","Validation: 150it [00:59,  2.51it/s]\n","\u001b[1m[\u001b[0m\u001b[1;36m299\u001b[0m seconds\u001b[1m]\u001b[0m This epoch is finished.\n","=============== \u001b[1;36m8\u001b[0m epoch ===============\n","\u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m seconds\u001b[1m]\u001b[0m Begin training\u001b[33m...\u001b[0m\n","Training: 100% 150/150 [01:28<00:00,  1.69it/s]\n","         Saving \u001b[1;36m8\u001b[0m epoch model checkpoint\u001b[33m...\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[1;36m89\u001b[0m seconds\u001b[1m]\u001b[0m Training has finished, validation is in progress\u001b[33m...\u001b[0m\n","Validation: 150it [00:59,  2.52it/s]\n","\u001b[1m[\u001b[0m\u001b[1;36m300\u001b[0m seconds\u001b[1m]\u001b[0m This epoch is finished.\n","=============== \u001b[1;36m9\u001b[0m epoch ===============\n","\u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m seconds\u001b[1m]\u001b[0m Begin training\u001b[33m...\u001b[0m\n","Training: 100% 150/150 [01:27<00:00,  1.71it/s]\n","         Saving \u001b[1;36m9\u001b[0m epoch model checkpoint\u001b[33m...\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[1;36m88\u001b[0m seconds\u001b[1m]\u001b[0m Training has finished, validation is in progress\u001b[33m...\u001b[0m\n","Validation: 150it [00:59,  2.53it/s]\n","\u001b[1m[\u001b[0m\u001b[1;36m298\u001b[0m seconds\u001b[1m]\u001b[0m This epoch is finished.\n","=============== \u001b[1;36m10\u001b[0m epoch ===============\n","\u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m seconds\u001b[1m]\u001b[0m Begin training\u001b[33m...\u001b[0m\n","Training: 100% 150/150 [01:27<00:00,  1.72it/s]\n","         Saving \u001b[1;36m10\u001b[0m epoch model checkpoint\u001b[33m...\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[1;36m87\u001b[0m seconds\u001b[1m]\u001b[0m Training has finished, validation is in progress\u001b[33m...\u001b[0m\n","Validation: 150it [00:59,  2.53it/s]\n","\u001b[1m[\u001b[0m\u001b[1;36m299\u001b[0m seconds\u001b[1m]\u001b[0m This epoch is finished.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"7GoAvyzx-Szf"},"execution_count":null,"outputs":[]}]}